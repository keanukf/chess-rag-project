{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b13a059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 16 of 33 games for player lachesisQ\n",
      "Uploaded 32 of 33 games for player lachesisQ\n",
      "Uploaded 33 of 33 games for player lachesisQ\n",
      "Data upload to Pinecone complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pinecone import Pinecone\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pinecone\n",
    "api_key = '801871e8-e0fa-4e25-abd2-62bdcfef9c2c'\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index = pc.Index('chess-games')\n",
    "\n",
    "# Load model directly\n",
    "model_name = 'bert-base-uncased'  # Correct BERT model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model uses the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "local_file_name = 'chess_games.csv'\n",
    "df = pd.read_csv(local_file_name)\n",
    "\n",
    "# Filter for rated games\n",
    "df = df[df['rated'] == True]\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['url', 'pgn', 'rated'], axis=1)\n",
    "\n",
    "# List of the eight players of interest\n",
    "players_of_interest = ['Hikaru', 'MagnusCarlsen', 'lachesisQ', 'ChessWarrior7197', 'GukeshDommaraju', 'GMWSO', 'LOVEVAE', 'FabianoCaruana']\n",
    "\n",
    "# Function to create embeddings from game data using BERT model\n",
    "def create_embeddings(rows):\n",
    "    texts = [f\"Game between {row['white_username']} (rating: {row['white_rating']}) and {row['black_username']} (rating: {row['black_rating']}) with result {row['result']}\" for _, row in rows.iterrows()]\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy().tolist()\n",
    "    return embeddings\n",
    "\n",
    "# Function to find games between specific players\n",
    "def find_games_between_players(dataframe, players):\n",
    "    games_between_players = []\n",
    "\n",
    "    # Iterate through each pair of players\n",
    "    for i, player1 in enumerate(players):\n",
    "        for player2 in players[i+1:]:\n",
    "            # Filter games where player1 and player2 played against each other\n",
    "            games = dataframe[((dataframe['white_username'] == player1) & (dataframe['black_username'] == player2)) |\n",
    "                              ((dataframe['white_username'] == player2) & (dataframe['black_username'] == player1))]\n",
    "            if not games.empty:\n",
    "                games_between_players.append(games)\n",
    "\n",
    "    # Concatenate all the games found into a single DataFrame\n",
    "    if games_between_players:\n",
    "        result_df = pd.concat(games_between_players)\n",
    "        return result_df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no games were found\n",
    "\n",
    "# Function to upload data to Pinecone with player-based namespaces, handling games between focused players\n",
    "def upload_to_pinecone(dataframe, players, batch_size=16, max_batch_size_bytes=4*1024*1024):\n",
    "    # Find games between the focused players\n",
    "    games_between_focused_players = find_games_between_players(dataframe, players)\n",
    "\n",
    "    for player in players:\n",
    "        # Filter games for the current player\n",
    "        player_games = dataframe[(dataframe['white_username'] == player) | (dataframe['black_username'] == player)]\n",
    "        namespace = player  # Use player name as namespace\n",
    "\n",
    "        # Upload player games in batches\n",
    "        for start_idx in range(0, len(player_games), batch_size):\n",
    "            batch = player_games.iloc[start_idx:start_idx + batch_size]\n",
    "            vectors = []\n",
    "            embeddings = create_embeddings(batch)\n",
    "\n",
    "            for idx, (embedding, (_, row)) in enumerate(zip(embeddings, batch.iterrows())):\n",
    "                metadata = {\n",
    "                    'time_control': row['time_control'],\n",
    "                    'end_time': row['end_time'],\n",
    "                    'time_class': row['time_class'],\n",
    "                    'rules': row['rules'],\n",
    "                    'white_username': row['white_username'],\n",
    "                    'white_rating': row['white_rating'],\n",
    "                    'black_username': row['black_username'],\n",
    "                    'black_rating': row['black_rating'],\n",
    "                    'result': row['result']\n",
    "                }\n",
    "                vectors.append((str(start_idx + idx), embedding, metadata))\n",
    "\n",
    "                # Check the batch size and upload if it exceeds the limit\n",
    "                batch_size_bytes = sum([len(json.dumps(v)) for v in vectors])\n",
    "                if batch_size_bytes >= max_batch_size_bytes:\n",
    "                    index.upsert(vectors, namespace=namespace)\n",
    "                    vectors = []\n",
    "\n",
    "            # Upload remaining vectors in the batch\n",
    "            if vectors:\n",
    "                index.upsert(vectors, namespace=namespace)\n",
    "            \n",
    "            print(f\"Uploaded {start_idx + len(batch)} of {len(player_games)} games for player {player}\")\n",
    "\n",
    "        # Duplicate games involving other focused players in their respective namespaces\n",
    "        for start_idx in range(0, len(games_between_focused_players), batch_size):\n",
    "            batch = games_between_focused_players.iloc[start_idx:start_idx + batch_size]\n",
    "            embeddings = create_embeddings(batch)\n",
    "            vectors = []\n",
    "\n",
    "            for idx, (embedding, (_, row)) in enumerate(zip(embeddings, batch.iterrows())):\n",
    "                if row['white_username'] == player or row['black_username'] == player:\n",
    "                    metadata = {\n",
    "                        'time_control': row['time_control'],\n",
    "                        'end_time': row['end_time'],\n",
    "                        'time_class': row['time_class'],\n",
    "                        'rules': row['rules'],\n",
    "                        'white_username': row['white_username'],\n",
    "                        'white_rating': row['white_rating'],\n",
    "                        'black_username': row['black_username'],\n",
    "                        'black_rating': row['black_rating'],\n",
    "                        'result': row['result']\n",
    "                    }\n",
    "                    other_namespace = row['white_username'] if row['black_username'] == player else row['black_username']\n",
    "                    vectors.append((str(start_idx + idx), embedding, metadata))\n",
    "\n",
    "                    # Check the batch size and upload if it exceeds the limit\n",
    "                    batch_size_bytes = sum([len(json.dumps(v)) for v in vectors])\n",
    "                    if batch_size_bytes >= max_batch_size_bytes:\n",
    "                        index.upsert(vectors, namespace=other_namespace)\n",
    "                        vectors = []\n",
    "\n",
    "            # Upload remaining vectors in the batch\n",
    "            if vectors:\n",
    "                index.upsert(vectors, namespace=other_namespace)\n",
    "            \n",
    "            print(f\"Uploaded {start_idx + len(batch)} of {len(games_between_focused_players)} duplicated games for player {player}\")\n",
    "\n",
    "# Upload the data\n",
    "upload_to_pinecone(df, players_of_interest)\n",
    "\n",
    "print(\"Data upload to Pinecone complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
